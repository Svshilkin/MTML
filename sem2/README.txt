# Машинное обучение "без учителя". Задача кластеризации. 

В практических примерах ниже показано:   

* как пользоваться инструментами визуального анализа для предварительной интерпретации кластеров 
* как проводить кластерный анализ 
* как строить прогноз принадлежности к кластерам новых наблюдений
* как оценивать точность кластеризации

*Модели*: иерархический и неиерархический кластерный анализ

*Данные*: load_iris

Данные в примере:
* **sepal length (cm)** - длина чашелистика (см)
* **sepal width (cm)** - ширина чашелистика (см)
* **petal length (cm)** - длина лепестка (см)
* **petal width (cm)** - ширина лепестка (см)

Задача состоит в разделении ирисов на группы в зависимости от  показателей(sepal length (cm) petal width (cm))

!!!1

!!!2

Можно предположить, что лучше всего будет сгруппировать данные на 4 группы. Тем не менее, рассмотрим метод для определения наилучшего количества кластеров.

## Определение оптимального количества кластеров для метода локтя

Здесь $w_{ij}$ = 1, если наблюдение относится к кластеру $j$ и 0 в противоположном случае, а $m_i$ - центроид кластера.

Одна из основных трудностей в обучении без учителя состоит в том, что мы не знаем точного ответа. В нашем наборе данных нет 
установленных данных о метках классов, поэтому для количественного определения качества кластеризации нам нужно использовать внутренние метрики - такие как внутрикластерная **SSE** (искажение или инерция):
$$SSE = \sum\limits_{i=1}^n\sum\limits_{j=1}^kw_{ij}(x_i - m_i)^2$$

Основываясь на внутрикластерной SSE, мы можем применить графический инструмент,
так называемый метод локтя, для оценки оптимального числа k кластеров для поставленной задачи. 
Интуитивно мы можем сказать, что если k увеличивается, то искажение уменьшается. 
Это вызвано тем, что образцы будут ближе к центроидам, которым они назначены. 
В основе метода локтя лежит идея, которая состоит в том, чтобы идентифицировать значение k в точке,
где искажение начинает увеличиваться быстрее всего, что станет понятнее, если мы построим график искажения для разных значений k.

!!!3

Как видно на графике выше, локоть расположен в k = 3, что свидетельствует о том, что k = 3 является хорошим выбором для этого набора данных.

!!!4

Сделаем построение и для 3-ёх групп:

!!!5

Теперь видим, что каждая группа точек покрашена в цвет соответствующего кластера, а центроиды расположены внутри множества точек. Тем не менее, попробуем оценить качество кластеризации в обоих вариантах.

## Количественная оценка качества кластеризации

Внутренняя метрика для оценки качества кластеризации (наряду с **SSE**) представлена силуэтным анализом
Силуэтный анализ может использоваться в качестве графического инструмента для построения графика меры плотности группировки образцов в кластерах. 
Чтобы вычислить силуэтный коэффициент наблюдения в нашем наборе данных, можно применить следующие три шага. 
1. Вычислить *внутриклассовую связность* $a_i$ как среднее расстояние между наблюдением и другими точками кластера
2. Вычислить *межкластерное разделение* $b_i$ от следующего ближайшего кластера как среднее расстояние между наблюдением $х_i$ и всеми наблюдениями в ближайшем кластере
3. Вычислить *силуэт* $s_i$:
$$s_i = (b_i - a_i)/\max(b_i,a_i).$$

$s_i$ принимает значения в диапазоне $[-1, 1]$. Идеальное совпадение - когда $s_i = 1.$

Посчитаем для k=3 кластеров:

!!!6

Средний коэффициент силуэта весьма близок к 0.5, что говорит о относительным качестве кластеризации.
Если силуэты зрительно значительно отличаются друг от друга по длине, то это является признаком *субоптимальной* кластеризации. Как правило, в этом случае центроиды кластеров стоят отдельно от множества точек кластера. 
Посчитаем средний силуэтный коэффициент для кластеризации $k=4$. 

Средний коэффициент силуэта --  0.4634141452435154

Его значение немного ниже, чем в предыдущем случае. Формально $k=3$ - более оптимальное разбиение.

## Сравнение результатов на обучающей и тестовой выборке
Посмотрим, как прогнозировать новых наблюдений принадлежность к кластерам, построенным по обучающим данным. Сравним значения средних силуэтных коэффициентов.

В обучающей выборке - 80% исходных наблюдений.

Добавляем к выборке дополнительный показатель.

!!!7

!!!8

Как видно на графике выше, заметных изменений не обнаружилось.

Обучаем алгоритм и считаем средний силуэтный коэффициент.

Средний коэффициент силуэта --  0.46394435413444274

Применяем модель к новым данным. Значение среднего силуэтного коэффициента незначительно ухудшилось. (Средний коэффициент силуэта --  0.4921130197472057)

#### Статистический анализ получившихся кластеров

!!!9

Визуально кластеры немного отличаются друг от друга. Судя по графикам плотности, по показателю sepal_length имеют различия, а по petal_width и sepal_width имеют некоторые сходства. По диаграммам разброса видно, что оба кластера образуют не совсем плотное множество точек, разбиение нестрогое.

## Оценка точности кластеризации с помощью Acc, сравнив оценки с фактическим разбиением на группы.

Acc для выборки с двумя показателями ("sepal length (cm)", "petal width (cm)"):
1) для разбиения на 2 кластера (Accuracy: 0.087)
2) для разбиения на 3 кластера (Accuracy: 0.493)
3) для разбиения на 4 кластера (Accuracy: 0.353)

Из оценки кластеризации следует, что алгоритм(для 3-ёх кластеров) достиг высокой точности в своей работе, указывая правильную категоризацию большинства объектов данных.

Acc для выборки с тремя показателями ("sepal length (cm)", "petal width (cm)", "sepal width (cm)"):
1) для разбиения на 2 кластера (Accuracy: 0.667)
2) для разбиения на 3 кластера (Accuracy: 0.507)
3) для разбиения на 4 кластера (Accuracy: 0.507)

Из оценки кластеризации следует, что алгоритм(при разбиении на 2 кластера) достиг высокой точности в своей работе, указывая правильную категоризацию большинства объектов данных.


